{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "TOaYaJljbizR"
      },
      "outputs": [],
      "source": [
        "import logging\n",
        "logging.basicConfig(filename=\"7AprInfo.log\", level=logging.INFO, format=\"%(asctime)s %(name)s %(message)s\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# answer 1\n",
        "Polynomial functions and kernel functions are both used as basis functions in machine learning algorithms, but they serve different purposes.\n",
        "\n",
        "A polynomial function is a function of the form f(x) = a_n x^n + a_{n-1} x^{n-1} + ... + a_1 x + a_0, where the coefficients a_i are real numbers and n is a non-negative integer. Polynomial functions are used to model relationships between variables in regression analysis, and they can also be used for classification tasks in machine learning.\n",
        "\n",
        "Kernel functions, on the other hand, are used in support vector machines (SVMs) to transform input data into a higher-dimensional feature space. This allows for the creation of non-linear decision boundaries between classes that cannot be separated by a linear boundary in the original input space. A common type of kernel function used in SVMs is the radial basis function (RBF) kernel, which is defined as K(x, y) = exp(-gamma ||x-y||^2), where gamma is a parameter that determines the width of the kernel and ||x-y||^2 is the squared Euclidean distance between two points x and y.\n",
        "\n",
        "While polynomial functions can also be used as kernel functions, they are typically less effective than other types of kernel functions such as the RBF kernel. This is because polynomial kernel functions can be less flexible and have difficulty capturing complex non-linear relationships between variables. However, in some cases, polynomial kernels can be useful for specific types of data and classification problems."
      ],
      "metadata": {
        "id": "CdocLC7Pdb9s"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# answer 2\n",
        "Implementing an SVM with a polynomial kernel in Python using Scikit-learn is relatively straightforward. Here is an example code snippet that demonstrates how to do this:\n",
        "\n"
      ],
      "metadata": {
        "id": "XHlVeoL6dedA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import svm\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Generate some example data\n",
        "X, y = make_classification(n_samples=1000, n_features=10, n_informative=5, n_classes=2, random_state=42)\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Create an SVM with a polynomial kernel\n",
        "svm_poly = svm.SVC(kernel='poly', degree=3)\n",
        "\n",
        "# Fit the SVM to the training data\n",
        "svm_poly.fit(X_train, y_train)\n",
        "\n",
        "# Predict the classes of the test data\n",
        "y_pred = svm_poly.predict(X_test)\n",
        "\n",
        "# Calculate the accuracy of the SVM on the test data\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "print(f\"Accuracy: {accuracy:.2f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2uYlvE0hdqWn",
        "outputId": "6903c490-5189-4b74-8a62-d38496a5e15b"
      },
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.88\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this code snippet, we first generate some example data using the make_classification function from Scikit-learn. We then split the data into training and testing sets using the train_test_split function.\n",
        "\n",
        "Next, we create an SVM with a polynomial kernel by instantiating the svm.SVC class with the kernel parameter set to 'poly' and the degree parameter set to 3. This creates an SVM with a third-degree polynomial kernel.\n",
        "\n",
        "We then fit the SVM to the training data using the fit method, and predict the classes of the test data using the predict method. Finally, we calculate the accuracy of the SVM on the test data using the accuracy_score function from Scikit-learn.\n",
        "\n",
        "Note that the degree parameter controls the degree of the polynomial kernel, and can be adjusted as needed. Higher degree polynomial kernels can capture more complex non-linear relationships in the data, but may also be more prone to overfitting."
      ],
      "metadata": {
        "id": "KudZDiw4dtJb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# answer 3\n",
        "In support vector regression (SVR), epsilon is a hyperparameter that controls the width of the epsilon-insensitive tube around the regression line. This tube defines the region within which errors are ignored and do not contribute to the loss function.\n",
        "\n",
        "Increasing the value of epsilon in SVR can have an impact on the number of support vectors. Specifically, as epsilon is increased, the size of the epsilon-insensitive tube also increases. This means that data points that were previously outside the tube and were not considered support vectors may now fall inside the tube and become support vectors.\n",
        "\n",
        "Conversely, decreasing the value of epsilon will result in a narrower epsilon-insensitive tube, causing some support vectors to fall outside of it and no longer be considered support vectors.\n",
        "\n",
        "In general, the number of support vectors in an SVR model can be influenced by a number of factors, including the choice of kernel function, the complexity of the data, and the choice of hyperparameters such as epsilon and the regularization parameter C. In some cases, increasing the value of epsilon may result in a simpler model with fewer support vectors, while in other cases it may lead to a more complex model with more support vectors. Therefore, it is important to experiment with different values of epsilon and other hyperparameters to find the best model for a given dataset."
      ],
      "metadata": {
        "id": "VbJhL2JIdzmP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# answer 4\n",
        "The performance of Support Vector Regression (SVR) is affected by several hyperparameters, including the choice of kernel function, the C parameter, the epsilon parameter, and the gamma parameter. In this answer, I will explain how each of these parameters works and provide examples of when you might want to increase or decrease its value.\n",
        "\n",
        "1. Kernel function: The kernel function maps the input space to a higher-dimensional feature space, which can make the data linearly separable. There are several types of kernel functions available in Scikit-learn, including linear, polynomial, and radial basis function (RBF) kernels. The choice of kernel function depends on the data and the problem you are trying to solve. For example, a linear kernel is suitable when the data is linearly separable, while an RBF kernel can handle more complex data that is not linearly separable. In general, the choice of kernel function can have a significant impact on the performance of SVR.\n",
        "\n",
        "2. C parameter: The C parameter controls the trade-off between the complexity of the model and the degree to which errors are tolerated. A small value of C will result in a wider epsilon-insensitive tube and a smoother regression curve, while a large value of C will result in a narrower tube and a more complex model that is less tolerant of errors. Choosing the optimal value of C depends on the amount of noise in the data and the complexity of the underlying relationship between the input and output variables. A smaller value of C can be useful in cases where the data is noisy or when the goal is to avoid overfitting, while a larger value of C can be useful in cases where the underlying relationship is complex and a high degree of accuracy is required.\n",
        "\n",
        "3. Epsilon parameter: The epsilon parameter controls the width of the epsilon-insensitive tube around the regression curve. This tube defines the region within which errors are ignored and do not contribute to the loss function. A larger value of epsilon will result in a wider tube and a more tolerant model that can handle larger errors, while a smaller value of epsilon will result in a narrower tube and a less tolerant model that is more sensitive to errors. The choice of epsilon depends on the amount of noise in the data and the desired level of accuracy.\n",
        "\n",
        "4. Gamma parameter: The gamma parameter is a parameter used by the RBF kernel and controls the width of the kernel function. A smaller value of gamma will result in a wider kernel and a smoother regression curve, while a larger value of gamma will result in a narrower kernel and a more complex model. A larger value of gamma can be useful in cases where the underlying relationship between the input and output variables is complex, while a smaller value of gamma can be useful in cases where the relationship is simpler.\n",
        "\n",
        "In general, the choice of hyperparameters in SVR is problem-dependent and requires experimentation to find the optimal values. Cross-validation can be used to evaluate the performance of the model with different hyperparameters. A general rule of thumb is to start with a small value of C and a wide epsilon-insensitive tube, and increase these values gradually if the model is underfitting. Similarly, if the model is overfitting, decrease the value of C and/or the width of the epsilon-insensitive tube. The choice of kernel function and gamma parameter should also be experimented with to find the best-performing model."
      ],
      "metadata": {
        "id": "Uym-qP-sd0sf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# answer 5"
      ],
      "metadata": {
        "id": "06kWcyBEfXdX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#a importing necessary libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "#from sklearn.linear_model  import LogisticRegression\n",
        "# from sklearn.tree import DecisionTreeClassifier\n",
        "# from sklearn.svm import SVC\n",
        "# from sklearn.naive_bayes import BernoulliNB\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\")\n",
        "%matplotlib inline"
      ],
      "metadata": {
        "id": "sbALnVwNf1qM"
      },
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#a load the dataset\n",
        "from sklearn.datasets import load_iris\n",
        "iris = load_iris()"
      ],
      "metadata": {
        "id": "zRQRc_7nr09v"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#b Split the dataset into a training set and a testing set\n",
        "X_train, X_test, y_train, y_test = train_test_split(iris.data, iris.target, test_size=0.2, random_state=42)"
      ],
      "metadata": {
        "id": "Qgs7p3-b8D4h"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#c Preprocess the data using StandardScaler\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)"
      ],
      "metadata": {
        "id": "nY32oFiI8fBJ"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#d Instance of the SVC classifier and train it on the training data\n",
        "from sklearn.svm import SVC\n",
        "svc = SVC()\n",
        "svc.fit(X_train_scaled, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "35JM1isEn71x",
        "outputId": "8ab1840b-8c15-4f71-8abc-c1e28cd6cfed"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SVC()"
            ],
            "text/html": [
              "<style>#sk-container-id-6 {color: black;background-color: white;}#sk-container-id-6 pre{padding: 0;}#sk-container-id-6 div.sk-toggleable {background-color: white;}#sk-container-id-6 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-6 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-6 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-6 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-6 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-6 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-6 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-6 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-6 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-6 div.sk-item {position: relative;z-index: 1;}#sk-container-id-6 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-6 div.sk-item::before, #sk-container-id-6 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-6 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-6 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-6 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-6 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-6 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-6 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-6 div.sk-label-container {text-align: center;}#sk-container-id-6 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-6 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" checked><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC()</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#e predict the labels of the testing data\n",
        "y_pred = svc.predict(X_test_scaled)"
      ],
      "metadata": {
        "id": "5Ne_c1LHpQTm"
      },
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#f Calculate the accuracy of the classifier on the testing set\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy:\", accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "veLrDVijqZUt",
        "outputId": "61befdfb-4090-40be-cf60-0553877b552d"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "conf_mat = confusion_matrix(y_test,y_pred)\n",
        "conf_mat"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xo8Xs6elqfgh",
        "outputId": "65b66b46-5ca0-4bbd-e441-a8ed799b5e7f"
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[10,  0,  0],\n",
              "       [ 0,  9,  0],\n",
              "       [ 0,  0, 11]])"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from the confusion matrix , we find that all the classes were classified with 100% accuracy as the diagonals are all ok\n",
        "tpA=conf_mat[0][0]\n",
        "tpB=conf_mat[1][1]\n",
        "tpC=conf_mat[2][2]\n",
        "#  accuracy, precision, recall and f1_score all will be one"
      ],
      "metadata": {
        "id": "CkPyCIHy5ftz"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#g Tune the hyperparameters of the SVC classifier using GridSearchCV or RandomiMedSearchCV to improve its performance\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "param_grid = {\n",
        "     'C': [0.1, 1, 5, 10],\n",
        "     'gamma': ['scale', 'auto'], \n",
        "     'kernel': ['linear', 'poly', 'rbf', 'sigmoid']\n",
        "}\n",
        "grid = GridSearchCV(SVC(), param_grid, refit=True, verbose=5)\n",
        "grid.fit(X_train_scaled, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "uSBXIPviXsVo",
        "outputId": "f3ff933d-b6a3-4b70-f7f2-cf10972ecf18"
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 32 candidates, totalling 160 fits\n",
            "[CV 1/5] END .C=0.1, gamma=scale, kernel=linear;, score=0.958 total time=   0.0s\n",
            "[CV 2/5] END .C=0.1, gamma=scale, kernel=linear;, score=0.958 total time=   0.0s\n",
            "[CV 3/5] END .C=0.1, gamma=scale, kernel=linear;, score=0.875 total time=   0.0s\n",
            "[CV 4/5] END .C=0.1, gamma=scale, kernel=linear;, score=1.000 total time=   0.0s\n",
            "[CV 5/5] END .C=0.1, gamma=scale, kernel=linear;, score=0.958 total time=   0.0s\n",
            "[CV 1/5] END ...C=0.1, gamma=scale, kernel=poly;, score=0.833 total time=   0.0s\n",
            "[CV 2/5] END ...C=0.1, gamma=scale, kernel=poly;, score=0.708 total time=   0.0s\n",
            "[CV 3/5] END ...C=0.1, gamma=scale, kernel=poly;, score=0.917 total time=   0.0s\n",
            "[CV 4/5] END ...C=0.1, gamma=scale, kernel=poly;, score=0.833 total time=   0.0s\n",
            "[CV 5/5] END ...C=0.1, gamma=scale, kernel=poly;, score=0.750 total time=   0.0s\n",
            "[CV 1/5] END ....C=0.1, gamma=scale, kernel=rbf;, score=0.875 total time=   0.0s\n",
            "[CV 2/5] END ....C=0.1, gamma=scale, kernel=rbf;, score=0.833 total time=   0.0s\n",
            "[CV 3/5] END ....C=0.1, gamma=scale, kernel=rbf;, score=0.833 total time=   0.0s\n",
            "[CV 4/5] END ....C=0.1, gamma=scale, kernel=rbf;, score=0.917 total time=   0.0s\n",
            "[CV 5/5] END ....C=0.1, gamma=scale, kernel=rbf;, score=0.833 total time=   0.0s\n",
            "[CV 1/5] END C=0.1, gamma=scale, kernel=sigmoid;, score=0.792 total time=   0.0s\n",
            "[CV 2/5] END C=0.1, gamma=scale, kernel=sigmoid;, score=1.000 total time=   0.0s\n",
            "[CV 3/5] END C=0.1, gamma=scale, kernel=sigmoid;, score=0.833 total time=   0.0s\n",
            "[CV 4/5] END C=0.1, gamma=scale, kernel=sigmoid;, score=0.833 total time=   0.0s\n",
            "[CV 5/5] END C=0.1, gamma=scale, kernel=sigmoid;, score=0.917 total time=   0.0s\n",
            "[CV 1/5] END ..C=0.1, gamma=auto, kernel=linear;, score=0.958 total time=   0.0s\n",
            "[CV 2/5] END ..C=0.1, gamma=auto, kernel=linear;, score=0.958 total time=   0.0s\n",
            "[CV 3/5] END ..C=0.1, gamma=auto, kernel=linear;, score=0.875 total time=   0.0s\n",
            "[CV 4/5] END ..C=0.1, gamma=auto, kernel=linear;, score=1.000 total time=   0.0s\n",
            "[CV 5/5] END ..C=0.1, gamma=auto, kernel=linear;, score=0.958 total time=   0.0s\n",
            "[CV 1/5] END ....C=0.1, gamma=auto, kernel=poly;, score=0.833 total time=   0.0s\n",
            "[CV 2/5] END ....C=0.1, gamma=auto, kernel=poly;, score=0.708 total time=   0.0s\n",
            "[CV 3/5] END ....C=0.1, gamma=auto, kernel=poly;, score=0.917 total time=   0.0s\n",
            "[CV 4/5] END ....C=0.1, gamma=auto, kernel=poly;, score=0.833 total time=   0.0s\n",
            "[CV 5/5] END ....C=0.1, gamma=auto, kernel=poly;, score=0.750 total time=   0.0s\n",
            "[CV 1/5] END .....C=0.1, gamma=auto, kernel=rbf;, score=0.875 total time=   0.0s\n",
            "[CV 2/5] END .....C=0.1, gamma=auto, kernel=rbf;, score=0.833 total time=   0.0s\n",
            "[CV 3/5] END .....C=0.1, gamma=auto, kernel=rbf;, score=0.833 total time=   0.0s\n",
            "[CV 4/5] END .....C=0.1, gamma=auto, kernel=rbf;, score=0.917 total time=   0.0s\n",
            "[CV 5/5] END .....C=0.1, gamma=auto, kernel=rbf;, score=0.833 total time=   0.0s\n",
            "[CV 1/5] END .C=0.1, gamma=auto, kernel=sigmoid;, score=0.792 total time=   0.0s\n",
            "[CV 2/5] END .C=0.1, gamma=auto, kernel=sigmoid;, score=1.000 total time=   0.0s\n",
            "[CV 3/5] END .C=0.1, gamma=auto, kernel=sigmoid;, score=0.833 total time=   0.0s\n",
            "[CV 4/5] END .C=0.1, gamma=auto, kernel=sigmoid;, score=0.833 total time=   0.0s\n",
            "[CV 5/5] END .C=0.1, gamma=auto, kernel=sigmoid;, score=0.917 total time=   0.0s\n",
            "[CV 1/5] END ...C=1, gamma=scale, kernel=linear;, score=0.958 total time=   0.0s\n",
            "[CV 2/5] END ...C=1, gamma=scale, kernel=linear;, score=1.000 total time=   0.0s\n",
            "[CV 3/5] END ...C=1, gamma=scale, kernel=linear;, score=0.833 total time=   0.0s\n",
            "[CV 4/5] END ...C=1, gamma=scale, kernel=linear;, score=1.000 total time=   0.0s\n",
            "[CV 5/5] END ...C=1, gamma=scale, kernel=linear;, score=0.958 total time=   0.0s\n",
            "[CV 1/5] END .....C=1, gamma=scale, kernel=poly;, score=0.958 total time=   0.0s\n",
            "[CV 2/5] END .....C=1, gamma=scale, kernel=poly;, score=0.917 total time=   0.0s\n",
            "[CV 3/5] END .....C=1, gamma=scale, kernel=poly;, score=0.917 total time=   0.0s\n",
            "[CV 4/5] END .....C=1, gamma=scale, kernel=poly;, score=0.958 total time=   0.0s\n",
            "[CV 5/5] END .....C=1, gamma=scale, kernel=poly;, score=0.875 total time=   0.0s\n",
            "[CV 1/5] END ......C=1, gamma=scale, kernel=rbf;, score=0.958 total time=   0.0s\n",
            "[CV 2/5] END ......C=1, gamma=scale, kernel=rbf;, score=1.000 total time=   0.0s\n",
            "[CV 3/5] END ......C=1, gamma=scale, kernel=rbf;, score=0.833 total time=   0.0s\n",
            "[CV 4/5] END ......C=1, gamma=scale, kernel=rbf;, score=1.000 total time=   0.0s\n",
            "[CV 5/5] END ......C=1, gamma=scale, kernel=rbf;, score=0.958 total time=   0.0s\n",
            "[CV 1/5] END ..C=1, gamma=scale, kernel=sigmoid;, score=0.958 total time=   0.0s\n",
            "[CV 2/5] END ..C=1, gamma=scale, kernel=sigmoid;, score=0.958 total time=   0.0s\n",
            "[CV 3/5] END ..C=1, gamma=scale, kernel=sigmoid;, score=0.833 total time=   0.0s\n",
            "[CV 4/5] END ..C=1, gamma=scale, kernel=sigmoid;, score=0.875 total time=   0.0s\n",
            "[CV 5/5] END ..C=1, gamma=scale, kernel=sigmoid;, score=0.917 total time=   0.0s\n",
            "[CV 1/5] END ....C=1, gamma=auto, kernel=linear;, score=0.958 total time=   0.0s\n",
            "[CV 2/5] END ....C=1, gamma=auto, kernel=linear;, score=1.000 total time=   0.0s\n",
            "[CV 3/5] END ....C=1, gamma=auto, kernel=linear;, score=0.833 total time=   0.0s\n",
            "[CV 4/5] END ....C=1, gamma=auto, kernel=linear;, score=1.000 total time=   0.0s\n",
            "[CV 5/5] END ....C=1, gamma=auto, kernel=linear;, score=0.958 total time=   0.0s\n",
            "[CV 1/5] END ......C=1, gamma=auto, kernel=poly;, score=0.958 total time=   0.0s\n",
            "[CV 2/5] END ......C=1, gamma=auto, kernel=poly;, score=0.917 total time=   0.0s\n",
            "[CV 3/5] END ......C=1, gamma=auto, kernel=poly;, score=0.917 total time=   0.0s\n",
            "[CV 4/5] END ......C=1, gamma=auto, kernel=poly;, score=0.958 total time=   0.0s\n",
            "[CV 5/5] END ......C=1, gamma=auto, kernel=poly;, score=0.875 total time=   0.0s\n",
            "[CV 1/5] END .......C=1, gamma=auto, kernel=rbf;, score=0.958 total time=   0.0s\n",
            "[CV 2/5] END .......C=1, gamma=auto, kernel=rbf;, score=1.000 total time=   0.0s\n",
            "[CV 3/5] END .......C=1, gamma=auto, kernel=rbf;, score=0.833 total time=   0.0s\n",
            "[CV 4/5] END .......C=1, gamma=auto, kernel=rbf;, score=1.000 total time=   0.0s\n",
            "[CV 5/5] END .......C=1, gamma=auto, kernel=rbf;, score=0.958 total time=   0.0s\n",
            "[CV 1/5] END ...C=1, gamma=auto, kernel=sigmoid;, score=0.958 total time=   0.0s\n",
            "[CV 2/5] END ...C=1, gamma=auto, kernel=sigmoid;, score=0.958 total time=   0.0s\n",
            "[CV 3/5] END ...C=1, gamma=auto, kernel=sigmoid;, score=0.833 total time=   0.0s\n",
            "[CV 4/5] END ...C=1, gamma=auto, kernel=sigmoid;, score=0.875 total time=   0.0s\n",
            "[CV 5/5] END ...C=1, gamma=auto, kernel=sigmoid;, score=0.917 total time=   0.0s\n",
            "[CV 1/5] END ...C=5, gamma=scale, kernel=linear;, score=1.000 total time=   0.0s\n",
            "[CV 2/5] END ...C=5, gamma=scale, kernel=linear;, score=1.000 total time=   0.0s\n",
            "[CV 3/5] END ...C=5, gamma=scale, kernel=linear;, score=0.833 total time=   0.0s\n",
            "[CV 4/5] END ...C=5, gamma=scale, kernel=linear;, score=1.000 total time=   0.0s\n",
            "[CV 5/5] END ...C=5, gamma=scale, kernel=linear;, score=1.000 total time=   0.0s\n",
            "[CV 1/5] END .....C=5, gamma=scale, kernel=poly;, score=0.958 total time=   0.0s\n",
            "[CV 2/5] END .....C=5, gamma=scale, kernel=poly;, score=0.958 total time=   0.0s\n",
            "[CV 3/5] END .....C=5, gamma=scale, kernel=poly;, score=0.875 total time=   0.0s\n",
            "[CV 4/5] END .....C=5, gamma=scale, kernel=poly;, score=1.000 total time=   0.0s\n",
            "[CV 5/5] END .....C=5, gamma=scale, kernel=poly;, score=0.917 total time=   0.0s\n",
            "[CV 1/5] END ......C=5, gamma=scale, kernel=rbf;, score=0.958 total time=   0.0s\n",
            "[CV 2/5] END ......C=5, gamma=scale, kernel=rbf;, score=1.000 total time=   0.0s\n",
            "[CV 3/5] END ......C=5, gamma=scale, kernel=rbf;, score=0.875 total time=   0.0s\n",
            "[CV 4/5] END ......C=5, gamma=scale, kernel=rbf;, score=1.000 total time=   0.0s\n",
            "[CV 5/5] END ......C=5, gamma=scale, kernel=rbf;, score=0.958 total time=   0.0s\n",
            "[CV 1/5] END ..C=5, gamma=scale, kernel=sigmoid;, score=0.708 total time=   0.0s\n",
            "[CV 2/5] END ..C=5, gamma=scale, kernel=sigmoid;, score=0.958 total time=   0.0s\n",
            "[CV 3/5] END ..C=5, gamma=scale, kernel=sigmoid;, score=0.750 total time=   0.0s\n",
            "[CV 4/5] END ..C=5, gamma=scale, kernel=sigmoid;, score=0.875 total time=   0.0s\n",
            "[CV 5/5] END ..C=5, gamma=scale, kernel=sigmoid;, score=0.875 total time=   0.0s\n",
            "[CV 1/5] END ....C=5, gamma=auto, kernel=linear;, score=1.000 total time=   0.0s\n",
            "[CV 2/5] END ....C=5, gamma=auto, kernel=linear;, score=1.000 total time=   0.0s\n",
            "[CV 3/5] END ....C=5, gamma=auto, kernel=linear;, score=0.833 total time=   0.0s\n",
            "[CV 4/5] END ....C=5, gamma=auto, kernel=linear;, score=1.000 total time=   0.0s\n",
            "[CV 5/5] END ....C=5, gamma=auto, kernel=linear;, score=1.000 total time=   0.0s\n",
            "[CV 1/5] END ......C=5, gamma=auto, kernel=poly;, score=0.958 total time=   0.0s\n",
            "[CV 2/5] END ......C=5, gamma=auto, kernel=poly;, score=0.958 total time=   0.0s\n",
            "[CV 3/5] END ......C=5, gamma=auto, kernel=poly;, score=0.917 total time=   0.0s\n",
            "[CV 4/5] END ......C=5, gamma=auto, kernel=poly;, score=1.000 total time=   0.0s\n",
            "[CV 5/5] END ......C=5, gamma=auto, kernel=poly;, score=0.917 total time=   0.0s\n",
            "[CV 1/5] END .......C=5, gamma=auto, kernel=rbf;, score=0.958 total time=   0.0s\n",
            "[CV 2/5] END .......C=5, gamma=auto, kernel=rbf;, score=1.000 total time=   0.0s\n",
            "[CV 3/5] END .......C=5, gamma=auto, kernel=rbf;, score=0.875 total time=   0.0s\n",
            "[CV 4/5] END .......C=5, gamma=auto, kernel=rbf;, score=1.000 total time=   0.0s\n",
            "[CV 5/5] END .......C=5, gamma=auto, kernel=rbf;, score=0.958 total time=   0.0s\n",
            "[CV 1/5] END ...C=5, gamma=auto, kernel=sigmoid;, score=0.708 total time=   0.0s\n",
            "[CV 2/5] END ...C=5, gamma=auto, kernel=sigmoid;, score=0.958 total time=   0.0s\n",
            "[CV 3/5] END ...C=5, gamma=auto, kernel=sigmoid;, score=0.750 total time=   0.0s\n",
            "[CV 4/5] END ...C=5, gamma=auto, kernel=sigmoid;, score=0.875 total time=   0.0s\n",
            "[CV 5/5] END ...C=5, gamma=auto, kernel=sigmoid;, score=0.875 total time=   0.0s\n",
            "[CV 1/5] END ..C=10, gamma=scale, kernel=linear;, score=0.958 total time=   0.0s\n",
            "[CV 2/5] END ..C=10, gamma=scale, kernel=linear;, score=1.000 total time=   0.0s\n",
            "[CV 3/5] END ..C=10, gamma=scale, kernel=linear;, score=0.833 total time=   0.0s\n",
            "[CV 4/5] END ..C=10, gamma=scale, kernel=linear;, score=1.000 total time=   0.0s\n",
            "[CV 5/5] END ..C=10, gamma=scale, kernel=linear;, score=1.000 total time=   0.0s\n",
            "[CV 1/5] END ....C=10, gamma=scale, kernel=poly;, score=0.958 total time=   0.0s\n",
            "[CV 2/5] END ....C=10, gamma=scale, kernel=poly;, score=0.958 total time=   0.0s\n",
            "[CV 3/5] END ....C=10, gamma=scale, kernel=poly;, score=0.875 total time=   0.0s\n",
            "[CV 4/5] END ....C=10, gamma=scale, kernel=poly;, score=1.000 total time=   0.0s\n",
            "[CV 5/5] END ....C=10, gamma=scale, kernel=poly;, score=0.917 total time=   0.0s\n",
            "[CV 1/5] END .....C=10, gamma=scale, kernel=rbf;, score=0.958 total time=   0.0s\n",
            "[CV 2/5] END .....C=10, gamma=scale, kernel=rbf;, score=0.958 total time=   0.0s\n",
            "[CV 3/5] END .....C=10, gamma=scale, kernel=rbf;, score=0.833 total time=   0.0s\n",
            "[CV 4/5] END .....C=10, gamma=scale, kernel=rbf;, score=1.000 total time=   0.0s\n",
            "[CV 5/5] END .....C=10, gamma=scale, kernel=rbf;, score=0.958 total time=   0.0s\n",
            "[CV 1/5] END .C=10, gamma=scale, kernel=sigmoid;, score=0.708 total time=   0.0s\n",
            "[CV 2/5] END .C=10, gamma=scale, kernel=sigmoid;, score=0.958 total time=   0.0s\n",
            "[CV 3/5] END .C=10, gamma=scale, kernel=sigmoid;, score=0.750 total time=   0.0s\n",
            "[CV 4/5] END .C=10, gamma=scale, kernel=sigmoid;, score=0.833 total time=   0.0s\n",
            "[CV 5/5] END .C=10, gamma=scale, kernel=sigmoid;, score=0.875 total time=   0.0s\n",
            "[CV 1/5] END ...C=10, gamma=auto, kernel=linear;, score=0.958 total time=   0.0s\n",
            "[CV 2/5] END ...C=10, gamma=auto, kernel=linear;, score=1.000 total time=   0.0s\n",
            "[CV 3/5] END ...C=10, gamma=auto, kernel=linear;, score=0.833 total time=   0.0s\n",
            "[CV 4/5] END ...C=10, gamma=auto, kernel=linear;, score=1.000 total time=   0.0s\n",
            "[CV 5/5] END ...C=10, gamma=auto, kernel=linear;, score=1.000 total time=   0.0s\n",
            "[CV 1/5] END .....C=10, gamma=auto, kernel=poly;, score=0.958 total time=   0.0s\n",
            "[CV 2/5] END .....C=10, gamma=auto, kernel=poly;, score=0.958 total time=   0.0s\n",
            "[CV 3/5] END .....C=10, gamma=auto, kernel=poly;, score=0.875 total time=   0.0s\n",
            "[CV 4/5] END .....C=10, gamma=auto, kernel=poly;, score=1.000 total time=   0.0s\n",
            "[CV 5/5] END .....C=10, gamma=auto, kernel=poly;, score=0.917 total time=   0.0s\n",
            "[CV 1/5] END ......C=10, gamma=auto, kernel=rbf;, score=0.958 total time=   0.0s\n",
            "[CV 2/5] END ......C=10, gamma=auto, kernel=rbf;, score=0.958 total time=   0.0s\n",
            "[CV 3/5] END ......C=10, gamma=auto, kernel=rbf;, score=0.833 total time=   0.0s\n",
            "[CV 4/5] END ......C=10, gamma=auto, kernel=rbf;, score=1.000 total time=   0.0s\n",
            "[CV 5/5] END ......C=10, gamma=auto, kernel=rbf;, score=0.958 total time=   0.0s\n",
            "[CV 1/5] END ..C=10, gamma=auto, kernel=sigmoid;, score=0.708 total time=   0.0s\n",
            "[CV 2/5] END ..C=10, gamma=auto, kernel=sigmoid;, score=0.958 total time=   0.0s\n",
            "[CV 3/5] END ..C=10, gamma=auto, kernel=sigmoid;, score=0.750 total time=   0.0s\n",
            "[CV 4/5] END ..C=10, gamma=auto, kernel=sigmoid;, score=0.833 total time=   0.0s\n",
            "[CV 5/5] END ..C=10, gamma=auto, kernel=sigmoid;, score=0.875 total time=   0.0s\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "GridSearchCV(estimator=SVC(),\n",
              "             param_grid={'C': [0.1, 1, 5, 10], 'gamma': ['scale', 'auto'],\n",
              "                         'kernel': ['linear', 'poly', 'rbf', 'sigmoid']},\n",
              "             verbose=5)"
            ],
            "text/html": [
              "<style>#sk-container-id-7 {color: black;background-color: white;}#sk-container-id-7 pre{padding: 0;}#sk-container-id-7 div.sk-toggleable {background-color: white;}#sk-container-id-7 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-7 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-7 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-7 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-7 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-7 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-7 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-7 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-7 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-7 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-7 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-7 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-7 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-7 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-7 div.sk-item {position: relative;z-index: 1;}#sk-container-id-7 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-7 div.sk-item::before, #sk-container-id-7 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-7 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-7 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-7 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-7 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-7 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-7 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-7 div.sk-label-container {text-align: center;}#sk-container-id-7 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-7 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-7\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(estimator=SVC(),\n",
              "             param_grid={&#x27;C&#x27;: [0.1, 1, 5, 10], &#x27;gamma&#x27;: [&#x27;scale&#x27;, &#x27;auto&#x27;],\n",
              "                         &#x27;kernel&#x27;: [&#x27;linear&#x27;, &#x27;poly&#x27;, &#x27;rbf&#x27;, &#x27;sigmoid&#x27;]},\n",
              "             verbose=5)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" ><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(estimator=SVC(),\n",
              "             param_grid={&#x27;C&#x27;: [0.1, 1, 5, 10], &#x27;gamma&#x27;: [&#x27;scale&#x27;, &#x27;auto&#x27;],\n",
              "                         &#x27;kernel&#x27;: [&#x27;linear&#x27;, &#x27;poly&#x27;, &#x27;rbf&#x27;, &#x27;sigmoid&#x27;]},\n",
              "             verbose=5)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" ><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: SVC</label><div class=\"sk-toggleable__content\"><pre>SVC()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-13\" type=\"checkbox\" ><label for=\"sk-estimator-id-13\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC()</pre></div></div></div></div></div></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#h Train the tuned classifier on the entire dataset\n",
        "best_svc = grid.best_estimator_\n",
        "# X_scaled = scaler.fit_transform(X)\n",
        "best_svc.fit(X_train_scaled, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "id": "b0C9M9c5ZUYj",
        "outputId": "fa4c962f-6230-405a-96ad-84882a379f53"
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "SVC(C=5, kernel='linear')"
            ],
            "text/html": [
              "<style>#sk-container-id-12 {color: black;background-color: white;}#sk-container-id-12 pre{padding: 0;}#sk-container-id-12 div.sk-toggleable {background-color: white;}#sk-container-id-12 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-12 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-12 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-12 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-12 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-12 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-12 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-12 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-12 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-12 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-12 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-12 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-12 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-12 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-12 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-12 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-12 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-12 div.sk-item {position: relative;z-index: 1;}#sk-container-id-12 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-12 div.sk-item::before, #sk-container-id-12 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-12 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-12 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-12 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-12 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-12 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-12 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-12 div.sk-label-container {text-align: center;}#sk-container-id-12 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-12 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-12\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(C=5, kernel=&#x27;linear&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-18\" type=\"checkbox\" checked><label for=\"sk-estimator-id-18\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(C=5, kernel=&#x27;linear&#x27;)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "grid.best_params_"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CLMsbgoLbubL",
        "outputId": "eeac8c88-116f-4311-b1b8-01e236b7cee9"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'C': 5, 'gamma': 'scale', 'kernel': 'linear'}"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#i Save the trained classifier to a file for future use\n",
        "import joblib\n",
        "joblib.dump(best_svc, 'svc_model.pkl')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kd7RjrXdY0Bx",
        "outputId": "2cac9266-28ec-45a5-e2b5-179e85c8072b"
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['svc_model.pkl']"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the trained classifier from the file\n",
        "loaded_classifier = joblib.load('svc_model.pkl')\n",
        "\n",
        "# Use the loaded classifier for prediction\n",
        "# X_test_scaled = scaler.transform(X_test)\n",
        "y_predx = loaded_classifier.predict(X_test_scaled)"
      ],
      "metadata": {
        "id": "V-sDWXt-aRXb"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#f Calculate the accuracy of the classifier on the testing set\n",
        "accuracy = accuracy_score(y_test, y_predx)\n",
        "print(\"Accuracy:\", accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D0SaVXRschO2",
        "outputId": "eae5c445-99ca-4196-ea3f-c3eeb1c08eee"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.9666666666666667\n"
          ]
        }
      ]
    }
  ]
}